{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6JAnDmzZC8p"
      },
      "outputs": [],
      "source": [
        "pip install langgraph langchain-google-genai langchain-community faiss-cpu pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "import pandas as pd\n",
        "from typing import Annotated, TypedDict, List\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
        "from langgraph.graph import StateGraph, END, add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.types import interrupt, Command"
      ],
      "metadata": {
        "id": "cTL7CJrOZN4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. SETUP API KEY ---\n",
        "# Replace \"PASTE_YOUR_KEY_HERE\" with your actual AIza... key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"Your_API_KEY\"\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"API Key: \")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ],
      "metadata": {
        "id": "jMKRFidYZN-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA: Note that Germany is \"Safe\" but expensive\n",
        "data = {\n",
        "    \"product_id\": [\"GPU-X100\", \"GPU-X100\", \"CPU-Z50\"],\n",
        "    \"location\": [\"Taiwan\", \"Germany\", \"California\"],\n",
        "    \"stock\": [0, 50, 100],  # Taiwan is out, Germany has stock\n",
        "    \"cost_modifier\": [1.0, 1.3, 1.0] # Germany is 30% more expensive\n",
        "}\n",
        "df_inventory = pd.DataFrame(data)\n",
        "\n",
        "news_feed = [\"URGENT: Super Typhoon 'Kuna' is hitting Taiwan. Ports closed.\"]\n",
        "vector_store = FAISS.from_texts(news_feed, embedding=embeddings)\n",
        "retriever = vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "qtSTNJMVZOBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. TOOLS (Capabilities) ---\n",
        "\n",
        "@tool\n",
        "def check_inventory(product_name: str):\n",
        "    \"\"\"Checks stock levels and locations for a product.\"\"\"\n",
        "    print(f\"üì¶ [Database] Checking stock for: {product_name}\")\n",
        "    matches = df_inventory[df_inventory[\"product_id\"].str.contains(product_name, case=False)]\n",
        "    if matches.empty:\n",
        "        return \"No stock found.\"\n",
        "    return matches.to_string(index=False)\n",
        "\n",
        "@tool\n",
        "def check_risks(location: str):\n",
        "    \"\"\"Checks for logistics risks (weather, strikes) in a location.\"\"\"\n",
        "    print(f\"üåç [Risk Scanner] Checking news for: {location}\")\n",
        "    docs = retriever.invoke(location)\n",
        "    return \"\\n\".join([doc.page_content for doc in docs]) if docs else \"No major risks reported.\"\n",
        "\n",
        "@tool\n",
        "def finalize_order(product_id: str, location: str, quantity: int):\n",
        "    \"\"\"\n",
        "    CRITICAL: Places the final shipping order.\n",
        "    Use this ONLY when the user explicitly asks to buy/ship.\n",
        "    \"\"\"\n",
        "    print(f\"\\nüö® [System] Attempting to finalize order from {location}...\")\n",
        "\n",
        "    # 1. Identify High Cost Logic (The \"Germany\" trap)\n",
        "    row = df_inventory[(df_inventory[\"product_id\"] == product_id) & (df_inventory[\"location\"] == location)]\n",
        "    cost_mod = row.iloc[0]['cost_modifier'] if not row.empty else 1.0\n",
        "\n",
        "    warning_msg = \"\"\n",
        "    if cost_mod > 1.0:\n",
        "        warning_msg = f\"‚ö†Ô∏è WARNING: Sourcing from {location} incurs a {(cost_mod-1)*100:.0f}% cost markup.\"\n",
        "\n",
        "    # 2. TRIGGER HUMAN APPROVAL (The Solution to Challenge 2 & 3)\n",
        "    # The code stops here and waits for input.\n",
        "    decision = interrupt(f\"Approve order for {quantity}x {product_id} from {location}? {warning_msg} (yes/no)\")\n",
        "\n",
        "    # 3. Handle Decision\n",
        "    print(f\"üë§ Human Admin said: {decision}\")\n",
        "\n",
        "    if decision.lower() == \"yes\":\n",
        "        return f\"‚úÖ SUCCESS: Order placed. Shipping {quantity} units from {location}. (Approved by Human)\"\n",
        "    else:\n",
        "        return f\"‚ùå ABORTED: Order cancelled by Human Admin due to cost/risk.\""
      ],
      "metadata": {
        "id": "FnodMcm-ZZVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. STATE & NODES ---\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "def agent_node(state: State):\n",
        "    \"\"\"The Brain: Maintains conversation history (Memory).\"\"\"\n",
        "    system_prompt = SystemMessage(content=\"\"\"\n",
        "    You are the Supply Chain Sentinel.\n",
        "    1. ALWAYS check inventory first.\n",
        "    2. ALWAYS check risks for the found location.\n",
        "    3. If stock is found in a safe location, propose it to the user.\n",
        "    4. NEVER finalize an order without calling 'finalize_order'.\n",
        "    \"\"\")\n",
        "\n",
        "    # Bind tools so the LLM knows it can use them\n",
        "    model = llm.bind_tools([check_inventory, check_risks, finalize_order])\n",
        "    return {\"messages\": [model.invoke([system_prompt] + state[\"messages\"])]}"
      ],
      "metadata": {
        "id": "2W0qSGfgZZZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. BUILD GRAPH ---\n",
        "\n",
        "workflow = StateGraph(State)\n",
        "workflow.add_node(\"agent\", agent_node)\n",
        "workflow.add_node(\"tools\", ToolNode([check_inventory, check_risks, finalize_order]))\n",
        "\n",
        "workflow.set_entry_point(\"agent\")\n",
        "workflow.add_conditional_edges(\"agent\", tools_condition)\n",
        "workflow.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "# MEMORY IS KEY: Use MemorySaver to persist across sessions\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ],
      "metadata": {
        "id": "lnfYbvB9ZZmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. EXECUTION: SOLVING THE CHALLENGES ---\n",
        "\n",
        "# We use the same thread_id to simulate \"Two Hours Later\"\n",
        "config = {\"configurable\": {\"thread_id\": \"manager_session_55\"}}\n",
        "\n",
        "print(\"\\n--- üïê SESSION 1: Initial Context ---\")\n",
        "# User asks about Taiwan. Agent finds stock is 0 and Typhoon exists.\n",
        "print(\"User: Can we ship GPU-X100 from Taiwan?\")\n",
        "app.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Can we ship GPU-X100 from Taiwan?\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "print(\"\\n--- üïë SESSION 2: Memory Test (2 Hours Later) ---\")\n",
        "# CHALLENGE 1 SOLVED: \"Those GPUs\" refers to previous context.\n",
        "# User pivots to Germany.\n",
        "print(\"User: What about 'those GPUs' we discussed? Are they available anywhere else?\")\n",
        "result = app.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What about those GPUs we discussed? Are they available anywhere else?\")]},\n",
        "    config=config\n",
        ")\n",
        "print(\"AI:\", result['messages'][-1].content)\n",
        "\n",
        "print(\"\\n--- üïí SESSION 3: The Critical Decision (HITL) ---\")\n",
        "# CHALLENGE 2 & 3 SOLVED: Agent tries to ship from Germany (expensive).\n",
        "# This triggers the 'finalize_order' tool, which triggers the INTERRUPT.\n",
        "print(\"User: Okay, ship them from Germany immediately.\")\n",
        "final_res = app.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Okay, ship them from Germany immediately.\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "# NOTE: The code will PAUSE here.\n",
        "# You (the Human) act as the manager.\n",
        "# Type 'yes' to approve the 30% markup, or 'no' to save money.\n",
        "\n",
        "# Handling the Resume (Simulating the UI callback)\n",
        "# In a real app, this happens when the user clicks a button.\n",
        "last_event = app.get_state(config).next\n",
        "if last_event:\n",
        "    # Resume with the decision\n",
        "    resume_command = Command(resume=\"yes\") # Change to \"no\" to test rejection\n",
        "    final_output = app.invoke(resume_command, config=config)\n",
        "    print(\"\\n‚úÖ Final AI Response:\\n\", final_output['messages'][-1].content)"
      ],
      "metadata": {
        "id": "MZv_sL5tZZpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8oOKIoSZODU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}